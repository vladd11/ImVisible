{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LYTNet",
      "provenance": [],
      "collapsed_sections": [
        "EkjpkRD7fRBZ",
        "xzwCXpStfeB5",
        "zxQj6pkNemvh",
        "e99VnVjyeJfY",
        "HC0SGTzngTD1"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOu/mdM7Pv1ckx968F8FTE8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladd11/ImVisible/blob/master/LYTNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Y_0p_VUFzXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDzijhs3Fyki",
        "outputId": "65213551-7cd6-43a1-f486-1c141ed72666"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import ImageFile, Image, ImageDraw\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as F\n",
        "import random, time\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "nupimCZbn0lt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "EkjpkRD7fRBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_loss(classifier, regression, points, mode):\n",
        "    #classifier is the predicted class\n",
        "    #regression is an array of predicted coordinates\n",
        "    #points is an array of ground truth coordinates\n",
        "    #mode is the ground truth class\n",
        "    alpha = 0.5\n",
        "    MSE = nn.MSELoss()\n",
        "    MSEl = MSE(regression, points)\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "    ce = cross_entropy(classifier, mode)\n",
        "    \n",
        "    loss = (ce*alpha + MSEl*(1-alpha)).float()\n",
        "    return loss, MSEl, ce"
      ],
      "metadata": {
        "id": "snKD_1u6f9ra"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def angle_difference(pred, label):\n",
        "    #pred is the array of coordinate predictions\n",
        "    #label is the array of ground truth coordinates\n",
        "    \n",
        "    #get all 4 coordinates from pred array\n",
        "    pred_x1 = pred[0][0]\n",
        "    pred_x2 = pred[0][2]\n",
        "    pred_y1 = pred[0][1]\n",
        "    pred_y2 = pred[0][3]\n",
        "    \n",
        "    pred_x_distance = pred_x1 - pred_x2 #distance between 2 x-coordinates\n",
        "    pred_y_distance = pred_y2 - pred_y1 #distance between 2 y-coordinates\n",
        "\n",
        "    pred_angle = math.atan2(pred_y_distance, pred_x_distance) #predicted angle between direction vector and x-axis\n",
        "    \n",
        "    #get all 4 coordinates from label array\n",
        "    act_x1 = label[0][0]\n",
        "    act_x2 = label[0][2]\n",
        "    act_y1 = label[0][1]\n",
        "    act_y2 = label[0][3]\n",
        "    \n",
        "    act_x_distance = act_x1 - act_x2\n",
        "    act_y_distance = act_y2 - act_y1\n",
        "    \n",
        "    actual_angle = math.atan2(act_y_distance, act_x_distance)\n",
        "    \n",
        "    return (pred_angle - actual_angle)*180/math.pi #returns difference between predicted and ground truth angles"
      ],
      "metadata": {
        "id": "trAsttBqfF9g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def startpoint_difference(pred, label):\n",
        "    #the startpoint will always be the second set of coordinates in the pred and label array\n",
        "    \n",
        "    x_distance = pred[0][2] - label[0][2]\n",
        "    y_distance = pred[0][3] - label[0][3]\n",
        "    \n",
        "    #distance between predicted and ground truth startpoints\n",
        "    distance = math.sqrt(x_distance*x_distance + y_distance*y_distance)\n",
        "    \n",
        "    return distance"
      ],
      "metadata": {
        "id": "F3xfQaCGfHGQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def endpoint_difference(pred, label):\n",
        "    #the endpoint will always be the first set of coordinates in the pred and label array\n",
        "    \n",
        "    x_distance = pred[0][0] - label[0][0]\n",
        "    y_distance = pred[0][1] - label[0][1]\n",
        "    \n",
        "    #distance between predicted and ground truth endpoints\n",
        "    distance = math.sqrt(x_distance*x_distance + y_distance*y_distance)\n",
        "    return distance"
      ],
      "metadata": {
        "id": "XrsZCTNBfLMB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def direction_performance(pred, label):\n",
        "    pred = pred.cpu().detach().numpy()\n",
        "    label = label.cpu().detach().numpy()\n",
        "    pred = pred.tolist()\n",
        "    label = label.tolist()\n",
        "    \n",
        "    #gets the absolute error\n",
        "    angle = math.fabs(angle_difference(pred,label))\n",
        "    start = math.fabs(startpoint_difference(pred,label))\n",
        "    end = math.fabs(endpoint_difference(pred,label))\n",
        "    \n",
        "    return angle, start, end"
      ],
      "metadata": {
        "id": "5CBgq-NbfM6T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image(image, title, points_pred, points_gt, factor):\n",
        "    #factor is used to convert the coordinates from between [0,1] to desired image coordinates\n",
        "    \n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    \n",
        "    #plots predicted coordinates\n",
        "    plt.scatter([points_pred[0]*factor*4,points_pred[2]*factor*4],[points_pred[1]*factor*3,points_pred[3]*factor*3], c = 'r')\n",
        "    #plots ground truth coordinates\n",
        "    plt.scatter([points_gt[0]*factor*4,points_gt[2]*factor*4],[points_gt[1]*factor*3,points_gt[3]*factor*3], c = 'b')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4r-MMQrDfCgS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LYTNetv1 classes"
      ],
      "metadata": {
        "id": "xzwCXpStfeB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.ReLU6(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "    )"
      ],
      "metadata": {
        "id": "9HdwFYEKfmEq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        nn.ReLU6(inplace=True)\n",
        "    )"
      ],
      "metadata": {
        "id": "El1EhPmJfnEZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = round(inp * expand_ratio)\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        if expand_ratio == 1:\n",
        "            self.conv = nn.Sequential(\n",
        "                # depthwise\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pointwise\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pointwise\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # depthwise\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                nn.ReLU6(inplace=True),\n",
        "                # pointwise\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)"
      ],
      "metadata": {
        "id": "ZNR7atxJfo7C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LYTNet(nn.Module):\n",
        "    def __init__(self, n_class=5, input_size_x = 768, input_size_y = 576, width_mult=1.):\n",
        "        super(LYTNet, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "        interverted_residual_setting = [\n",
        "            # t, c, n, s\n",
        "            [1, 16, 1, 1],\n",
        "            [6, 24, 2, 2],\n",
        "            [6, 32, 1, 2],\n",
        "            [6, 64, 3, 2],\n",
        "            [6, 96, 1, 1],\n",
        "            [6, 160, 2, 2],\n",
        "            [6, 320, 1, 1],\n",
        "        ]\n",
        "\n",
        "        #first layer\n",
        "        assert input_size_x % 64 == 0\n",
        "        assert input_size_y % 64 == 0\n",
        "        input_channel = int(input_channel * width_mult)\n",
        "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
        "        self.features = [conv_bn(3, input_channel, 2)]\n",
        "        \n",
        "        #bottleneck blocks\n",
        "        for t, c, n, s in interverted_residual_setting:\n",
        "            output_channel = int(c * width_mult)\n",
        "            for i in range(n):\n",
        "                if i == 0:\n",
        "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
        "                else:\n",
        "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "        \n",
        "        #last convolutional layer\n",
        "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
        "\n",
        "        self.features = nn.Sequential(*self.features,\n",
        "                                      nn.Dropout(0.1))\n",
        "\n",
        "        #classfier section of the network\n",
        "        self.classifier_light = nn.Sequential(\n",
        "            nn.Linear(self.last_channel, 160),\n",
        "            nn.BatchNorm1d(160),\n",
        "            nn.ReLU6(inplace = True),\n",
        "            nn.Linear(160, 5),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "        \n",
        "        # regression for direction\n",
        "        self.regression_direction = nn.Sequential(\n",
        "            nn.Linear(self.last_channel, 80),\n",
        "            nn.BatchNorm1d(80),\n",
        "            nn.ReLU6(inplace = True),\n",
        "            nn.Linear(80, 4)\n",
        "        )\n",
        "        \n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.mean(3).mean(2)\n",
        "        x1 = self.classifier_light(x)\n",
        "        x2 = self.regression_direction(x)\n",
        "        return x1, x2\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "                nn.init.xavier_normal_(m.weight.data)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()"
      ],
      "metadata": {
        "id": "ayRkgRzeewJB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LYTNet dataset class"
      ],
      "metadata": {
        "id": "zxQj6pkNemvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficLightDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file, img_dir, transformation = True):\n",
        "        self.labels = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transformation = transformation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "        img_name = os.path.join(self.img_dir, self.labels.iloc[index, 0]) #gets image name in csv file\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        light_mode = self.labels.iloc[index, 1] #mode of the traffic light\n",
        "        block = self.labels.iloc[index,6] #label of blocked or unblocked\n",
        "        points = self.labels.iloc[index, 2:6] #midline coordinates\n",
        "        points = [points[0]/4032, points[1]/3024, points[2]/4032, points[3]/3024] #normalize coordinate values to be between [0,1]\n",
        "\n",
        "        if self.transformation:            \n",
        "            #random horizontal flip with 50% probability\n",
        "            num = random.random()\n",
        "            if num >= 0.5:\n",
        "                image = F.hflip(image)\n",
        "                #flip x coordinates when entire image is flipped\n",
        "                points[0] = 1 - points[0] \n",
        "                points[2] = 1 - points[2]\n",
        "            \n",
        "            #random crop\n",
        "            cp = [points[0]*876, (1-points[1])*657, 876*points[2], (1-points[3])*657] #convert points to cartesian coordinates\n",
        "            #shifts to determine what region to crop\n",
        "            shiftx = random.randint(0, 108) \n",
        "            shifty = random.randint(0, 81)\n",
        "\n",
        "            with np.errstate(all=\"raise\"):\n",
        "                try: m = (cp[1]-cp[3])/(cp[0]-cp[2]) #slope\n",
        "                except: m = 10000000000000000 #prevent divide by zero error\n",
        "\n",
        "            b = cp[1] - m*cp[0] #y-intercept\n",
        "            \n",
        "            #changing the coordinates based on the new cropped area\n",
        "            if(shiftx > cp[0]): \n",
        "                cp[0] = shiftx\n",
        "                cp[1] = (cp[0]*m + b)\n",
        "            elif((768+shiftx) < cp[0]):\n",
        "                cp[0] = (768+shiftx)\n",
        "                cp[1] = (cp[0]*m + b)\n",
        "            if(shiftx > cp[2]): \n",
        "                cp[2] = shiftx\n",
        "                cp[3] = (cp[2]*m + b)\n",
        "            elif((768+shiftx) < cp[2]):\n",
        "                cp[2] = (768+shiftx)\n",
        "                cp[3] = (cp[2]*m + b)\n",
        "            if(657-shifty < cp[1]): \n",
        "                cp[1] = 657-shifty\n",
        "                cp[0] = (cp[1]-b)/m if (cp[1]-b)/m>0 else 0\n",
        "#            elif((657-576-shifty) > cp[1]):\n",
        "#                cp[0] = (657-576-shifty-b)/m\n",
        "#                cp[1] = 0\n",
        "#                cp[2] = (657-576-shifty-b)/m\n",
        "#                cp[3] = 0\n",
        "            if(657-576-shifty > cp[3]): \n",
        "                cp[3] = 657-576-shifty\n",
        "                cp[2] = (cp[3]-b)/m\n",
        "#            elif((657-shifty) < cp[3]):\n",
        "#                cp[3] = 657-shifty\n",
        "#                cp[2] = (657-shifty-b)/m\n",
        "#                cp[1] = 657-shifty\n",
        "#                cp[0] = (657-shifty-b)/m\n",
        "\n",
        "            #converting the coordinates from a 876x657 image to a 768x576 image\n",
        "            cp[0] -= shiftx\n",
        "            cp[1] -= (657-576-shifty)\n",
        "            cp[2] -= shiftx\n",
        "            cp[3] -= (657-576-shifty)\n",
        "\n",
        "            #converting the cartesian coordinates back to image coordinates\n",
        "            points = [cp[0]/768, 1-cp[1]/576, cp[2]/768, 1-cp[3]/576]\n",
        "            \n",
        "            image = F.crop(image, shifty, shiftx, 576, 768)\n",
        "            transform = transforms.Compose([transforms.ColorJitter(0.05,0.05,0.05,0.01)])\n",
        "            image = transform(image)\n",
        "        \n",
        "        #normalize image\n",
        "        #image = transforms.functional.to_tensor(image)\n",
        "        #image = transforms.functional.normalize(image, mean = [120.56737612047593, 119.16664454573734, 113.84554638827127], std=[66.32028460114392, 65.09469952002551, 65.67726614496246])\n",
        "        \n",
        "        image = np.transpose(image, (2, 0, 1))\n",
        "        points = torch.FloatTensor(points)\n",
        "        \n",
        "        #combine all the info into a dictionary\n",
        "        final_label = {'image': image, 'mode':light_mode, 'points': points, 'block': block}\n",
        "        return final_label"
      ],
      "metadata": {
        "id": "qBnEg6YCefwh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "e99VnVjyeJfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EQ0fYgiUcW_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MAX_EPOCHS = 800\n",
        "INIT_LR = 0.001\n",
        "WEIGHT_DECAY = 0.00005\n",
        "LR_DROP_MILESTONES = [400,600]\n",
        "\n",
        "train_file_dir = '/gdrive/MyDrive/Colab Notebooks/lights/training_file.csv'\n",
        "valid_file_dir = '/gdrive/MyDrive/Colab Notebooks/lights/validation_file.csv'\n",
        "train_img_dir = '/gdrive/MyDrive/Colab Notebooks/lights/dataset'\n",
        "valid_img_dir = '/gdrive/MyDrive/Colab Notebooks/lights/validation_dataset'\n",
        "save_path = '/gdrive/MyDrive/Colab Notebooks/lights'\n",
        "\n",
        "train_dataset = TrafficLightDataset(csv_file = train_file_dir, img_dir = train_img_dir)\n",
        "valid_dataset = TrafficLightDataset(csv_file = valid_file_dir, img_dir = valid_img_dir)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "net = LYTNet()\n",
        "\n",
        "if cuda_available:\n",
        "    net = net.cuda()\n",
        "\n",
        "loss_fn = my_loss\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = INIT_LR, weight_decay = 0.000005 )\n",
        "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, LR_DROP_MILESTONES)\n",
        "\n",
        "#storing all data during training\n",
        "train_losses = [] #stores the overall training loss at each epoch\n",
        "train_MSE = [] #stores the MSE loss during training at each epoch\n",
        "train_CE = [] #stores the cross entropy loss during training at each epoch\n",
        "valid_losses = [] #stores the overall validation loss at each epoch\n",
        "valid_MSE = [] #stores the MSE loss during validation at each epoch\n",
        "valid_CE = [] #stores the cross entropy loss during validation at each epoch\n",
        "train_accuracies = [] #stores the training accuracy of the network at each epoch\n",
        "valid_accuracies = [] #stores the validation accuracy of the network at each epoch\n",
        "val_angles = [] #stores the average angle error of the network during validation at each epoch\n",
        "val_start = [] #stores the average startpoint error of the network during validation at each epoch\n",
        "val_end = [] #stores the average endpoint error of the network during validation at each epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsCU8DGVoxUc",
        "outputId": "5f2f8091-2ee9-4bc3-f3a7-5606a5616003"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(MAX_EPOCHS):\n",
        "    \n",
        "    ##########\n",
        "    #TRAINING#\n",
        "    ########## \n",
        "    \n",
        "    net.train()\n",
        "    \n",
        "    running_loss = 0.0 #stores the total loss for the epoch\n",
        "    running_loss_MSE = 0.0 #stores the total MSE loss for the epoch\n",
        "    running_loss_cross_entropy = 0.0 #store the total cross entropy loss for the epoch\n",
        "    angle_error = 0.0 #stores average angle error for the epoch\n",
        "    startpoint_error = 0.0 #stores average startpoint error for the epoch\n",
        "    endpoint_error = 0.0 #stores average endpoint error for the epoch\n",
        "    train_correct = 0 #stores total number of correctly predicted images during training for the epcoh\n",
        "    train_total = 0 #stores total number of batches processed at each epoch\n",
        "    \n",
        "    for j, data in enumerate(train_dataloader, 0): \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        train_total += 1\n",
        "        \n",
        "        images = data['image'].type(torch.FloatTensor)\n",
        "        mode = data['mode'] #index of traffic light mode\n",
        "        points = data['points'] #array of midline coordinates\n",
        "        \n",
        "        if cuda_available:\n",
        "            images = images.cuda()\n",
        "            mode = mode.cuda()\n",
        "            points = points.cuda()\n",
        "        \n",
        "        pred_classes, pred_direc = net(images)\n",
        "        _, predicted = torch.max(pred_classes, 1) #finds index of largest probability\n",
        "        train_correct += (predicted == mode).sum().item() #increments train_correct if predicted index is correct\n",
        "        loss, MSE, cross_entropy = loss_fn(pred_classes, pred_direc, points, mode)\n",
        "        angle, start, end = direction_performance(pred_direc, points)\n",
        "        angle_error += angle\n",
        "        endpoint_error += end\n",
        "        startpoint_error += start\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        running_loss_MSE += MSE.item()\n",
        "        running_loss_cross_entropy += cross_entropy.item()\n",
        "\n",
        "    print('Epoch: ' + str(epoch+1))\n",
        "    print('Average training loss: ' + str(running_loss/(j+1)))\n",
        "    print('Average training MSE loss: ' + str(running_loss_MSE/(j+1)))\n",
        "    print('Average training cross entropy loss: ' + str(running_loss_cross_entropy/(j+1)))\n",
        "    print('Training accuracy: ' + str(train_correct/train_total/BATCH_SIZE))\n",
        "\n",
        "    train_MSE.append(running_loss_MSE/train_total)\n",
        "    train_CE.append(running_loss_cross_entropy/train_total)\n",
        "    train_losses.append(running_loss/train_total) \n",
        "    train_accuracies.append(train_correct/train_total/32*100) \n",
        "            \n",
        "    lr_scheduler.step(epoch + 1) #decrease learning rate if at desired epoch   \n",
        "    \n",
        "    ############\n",
        "    #VALIDATION#\n",
        "    ############ \n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    tp = {'0':0, '1':0, '2':0, '3':0, '4':0} #stores number of true positives for each class\n",
        "    fp = {'0':0, '1':0, '2':0, '3':0, '4':0} #stores number of false positives for each class\n",
        "    fn = {'0':0, '1':0, '2':0, '3':0, '4':0} #stores number of false negatives for each class\n",
        "    \n",
        "    precisions = [] #stores the precision for each class\n",
        "    recalls = [] #stores the recall for each class\n",
        "    \n",
        "    #stores losses and errors for network during validation\n",
        "    val_running_loss = 0\n",
        "    val_mse_loss = 0\n",
        "    val_ce_loss = 0\n",
        "    val_angle_error = 0\n",
        "    val_start_error = 0\n",
        "    val_end_error = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for k, data in enumerate(valid_dataloader, 0):\n",
        "            \n",
        "            images = data['image'].type(torch.FloatTensor)\n",
        "            mode = data['mode']\n",
        "            points = data['points']\n",
        "            \n",
        "            if cuda_available:\n",
        "                images = images.cuda()\n",
        "                mode = mode.cuda()\n",
        "                points = points.cuda()\n",
        "            \n",
        "            pred_classes, pred_direc = net(images)\n",
        "            _, predicted = torch.max(pred_classes, 1)\n",
        "            val_correct += (predicted == mode).sum().item()\n",
        "            val_total += 1\n",
        "            \n",
        "            #incorrect prediction\n",
        "            if (predicted == mode).sum().item() == 0:\n",
        "                fp[str(predicted.cpu().numpy()[0])] += 1 #increments predicted class's false positive count by one\n",
        "                fn[str(mode.cpu().numpy()[0])] += 1 #increments correct class's false negative count by one\n",
        "            \n",
        "            #correct prediction\n",
        "            if (predicted == mode).sum().item() == 1: \n",
        "                tp[str(predicted.cpu().numpy()[0])] += 1 #increments correct class's true positive count by one\n",
        "            \n",
        "            loss, MSE, cross_entropy = loss_fn(pred_classes, pred_direc, points, mode)\n",
        "            val_running_loss += loss.item()\n",
        "            val_mse_loss += MSE.item()\n",
        "            val_ce_loss += cross_entropy.item()\n",
        "            \n",
        "            angle, start, end = direction_performance(pred_direc, points)\n",
        "            val_angle_error += angle\n",
        "            val_start_error += start\n",
        "            val_end_error += end\n",
        "            \n",
        "        #calculates precision and recalls for each class given fp, tp, fn\n",
        "        #try excepts are used to prevent division by zero errors\n",
        "        try:red_precision = tp['0']/(tp['0'] + fp['0'])\n",
        "        except: red_precision = 0\n",
        "        precisions.append(red_precision)\n",
        "        try: red_recall = tp['0']/(tp['0'] + fn['0'])\n",
        "        except: red_recall = 0\n",
        "        recalls.append(red_recall)\n",
        "        \n",
        "        try: green_precision = tp['1']/(tp['1'] + fp['1'])\n",
        "        except: green_precision = 0\n",
        "        precisions.append(green_precision)\n",
        "        try: green_recall = tp['1']/(tp['1'] + fn['1'])\n",
        "        except: green_recall = 0\n",
        "        recalls.append(green_recall)\n",
        "        \n",
        "        try: countdown_green_precision = tp['2']/(tp['2'] + fp['2'])\n",
        "        except: countdown_green_precision = 0\n",
        "        precisions.append(countdown_green_precision)\n",
        "        try: countdown_green_recall = tp['2']/(tp['2'] + fn['2'])\n",
        "        except: countdown_green_recall = 0\n",
        "        recalls.append(countdown_green_recall)\n",
        "        \n",
        "        try: countdown_blank_precision = tp['3']/(tp['3'] + fp['3'])\n",
        "        except: countdown_blank_precision = 0\n",
        "        precisions.append(countdown_blank_precision)\n",
        "        try: countdown_blank_recall = tp['3']/(tp['3'] + fn['3'])\n",
        "        except: countdown_blank_recall = 0\n",
        "        recalls.append(countdown_blank_recall)\n",
        "        \n",
        "        try: none_precision = tp['4']/(tp['4'] + fp['4']) \n",
        "        except: none_precision = 0\n",
        "        precisions.append(none_precision)\n",
        "        try: none_recall = tp['4']/(tp['4'] + fn['4'])\n",
        "        except: none_recall = 0\n",
        "        recalls.append(none_recall)\n",
        "        \n",
        "        print(\"Average validation loss: \" + str(val_running_loss/val_total))\n",
        "        print(\"Average validation MSE loss: \" + str(val_mse_loss/val_total))\n",
        "        print(\"Average validation cross entropy loss: \" + str(val_ce_loss/val_total))\n",
        "        print(\"Validation accuracy: \" + str(100*val_correct/val_total))\n",
        "        \n",
        "        valid_accuracies.append(100*val_correct/val_total)\n",
        "        valid_losses.append(val_running_loss/val_total)\n",
        "        valid_MSE.append(val_mse_loss/val_total)\n",
        "        valid_CE.append(val_ce_loss/val_total)\n",
        "        \n",
        "        print(\"Precisions: \" + str(precisions))\n",
        "        print(\"Recalls: \" + str(recalls))\n",
        "        print(\"Angle Error: \" + str(val_angle_error/val_total))\n",
        "        print(\"Startpoint Error: \" + str(val_start_error/val_total))\n",
        "        print(\"Endpoint Error: \" + str(val_end_error/val_total))\n",
        "        \n",
        "        val_angles.append(val_angle_error/val_total)\n",
        "        val_start.append(val_start_error/val_total)\n",
        "        val_end.append(val_end_error/val_total)\n",
        "        \n",
        "        #graphs average losses every epoch_num of epochs\n",
        "        epoch_num = 100\n",
        "        if epoch % epoch_num == (epoch_num - 1):\n",
        "            plt.title('Train and Validation losses')\n",
        "            plt.plot(train_losses)\n",
        "            plt.plot(valid_losses)\n",
        "            plt.show()\n",
        "            \n",
        "        #stores the network and optimizer weights every 200th epoch\n",
        "        if epoch%50 == 49:\n",
        "            states = {\n",
        "                    'epoch': epoch+1,\n",
        "                    'state_dict': net.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict()\n",
        "                    }\n",
        "            torch.save(states, save_path + '_epoch_' + str(epoch+1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "YGIsT8VGlpks",
        "outputId": "4cddf712-4d17-47a5-b35e-06c104ceca97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-babd74efbfc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#stores total number of batches processed at each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plots training and validation loss\n",
        "plt.title('train and validation loss')\n",
        "plt.plot(valid_losses)\n",
        "plt.plot(train_losses)\n",
        "plt.savefig(save_path + '_losses')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5k3EmxN1J4SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plots training and validation cross entropy loss\n",
        "plt.title('train and valid cross entropy')\n",
        "plt.plot(train_CE)\n",
        "plt.plot(valid_CE)\n",
        "plt.savefig(save_path + 'train_valid_ce')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bNAm5N85J6LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plots training and validation MSE loss\n",
        "plt.title('train and valid MSE')\n",
        "plt.plot(train_MSE)\n",
        "plt.plot(valid_MSE)\n",
        "plt.savefig(save_path + 'train_valid_MSE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qQVHFXqdJ7qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plots training and validation accuracies\n",
        "plt.title('train and validation accuracies')\n",
        "plt.plot(valid_accuracies)\n",
        "plt.plot(train_accuracies)\n",
        "plt.savefig(save_path + '_accuracies')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LFFQiKPgJ9lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save final network weights\n",
        "torch.save(net.state_dict(), save_path + '_final_weights')"
      ],
      "metadata": {
        "id": "-hCwYrO5J-94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LYTNet testing"
      ],
      "metadata": {
        "id": "HC0SGTzngTD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "\n",
        "test_file_loc = '/gdrive/MyDrive/Colab Notebooks/lights/testing_file.csv'\n",
        "test_image_directory = '/gdrive/MyDrive/Colab Notebooks/lights/images'\n",
        "MODEL_PATH = '/gdrive/MyDrive/Colab Notebooks/lights/LytNetV2_weights'\n",
        "\n",
        "dataset = TrafficLightDataset(csv_file = test_file_loc, img_dir = test_image_directory)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "net = LYTNet()\n",
        "if cuda_available:\n",
        "    checkpoint = torch.load(MODEL_PATH)\n",
        "else:\n",
        "    checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
        "net.load_state_dict(checkpoint)\n",
        "net.eval()\n",
        "\n",
        "if cuda_available:\n",
        "    net = net.cuda()\n",
        "\n",
        "loss_fn = my_loss\n",
        "\n",
        "#storing data\n",
        "running_loss = 0\n",
        "running_test_angle = 0\n",
        "running_test_start = 0\n",
        "running_test_end = 0\n",
        "\n",
        "#errors when zebra crossing is blocked\n",
        "running_angle_block = 0\n",
        "running_start_block = 0\n",
        "running_end_block = 0\n",
        "block_count = 0\n",
        "\n",
        "#errors when zebra crossing is unblocked\n",
        "running_angle_unblock = 0\n",
        "running_start_unblock = 0\n",
        "running_end_unblock = 0\n",
        "unblock_count = 0\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "tp = {'0':0, '1':0, '2':0, '3':0, '4':0}\n",
        "fp = {'0':0, '1':0, '2':0, '3':0, '4':0}\n",
        "fn = {'0':0, '1':0, '2':0, '3':0, '4':0}\n",
        "classes = {'0':'red', '1':'green', '2':'none', '3':'countdown_blank', '4':'countdown_green'}\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    \n",
        "    for i, data in enumerate(dataloader):\n",
        "        \n",
        "        images = data['image'].type(torch.FloatTensor)\n",
        "        mode = data['mode']\n",
        "        points = data['points']\n",
        "        blocked = data['block'] #tag for blocked zebra crossing\n",
        "        \n",
        "        if cuda_available:\n",
        "            images = images.cuda()\n",
        "            mode = mode.cuda()\n",
        "            points = points.cuda()\n",
        " \n",
        "        pred_classes, pred_direc = net(images)\n",
        "        _, predicted = torch.max(pred_classes, 1)\n",
        "        \n",
        "        #correct prediction\n",
        "        if (predicted == mode).sum().item() == 1:\n",
        "            correct += 1\n",
        "            tp[str(predicted.cpu().numpy()[0])] += 1\n",
        "        \n",
        "        #incorrect prediction\n",
        "        if (predicted == mode).sum().item() == 0:\n",
        "            predicted_idx = str(predicted.cpu().numpy()[0])\n",
        "            gt_idx = str(mode.cpu().numpy()[0])\n",
        "            fp[predicted_idx] += 1\n",
        "            fn[gt_idx] += 1\n",
        "            \n",
        "            #display image when incorrect\n",
        "            image = images.cpu().numpy()[0]\n",
        "            image = np.transpose(image, (1,2,0))\n",
        "            image = image.astype(int)\n",
        "            \n",
        "            title = 'predicted: ' + classes[predicted_idx] + ' ground_truth: ' + classes[gt_idx] + ' ' + str(i+1)            \n",
        "            ax = plt.subplot()\n",
        "            ax.axis('on')\n",
        "            pred_points = pred_direc.cpu().detach().numpy()[0].tolist()\n",
        "            gt_points = points.cpu().detach().numpy()[0]\n",
        "            \n",
        "            display_image(image,title,pred_points, gt_points, 192) #factor is 192 because 4*192 = 768\n",
        "\n",
        "        loss, MSE, cross_entropy =  loss_fn(pred_classes, pred_direc, points, mode)\n",
        "        running_loss += loss.item()\n",
        "        angle, start, end = direction_performance(pred_direc, points)\n",
        "        \n",
        "        if(blocked[0] == \"blocked\"):\n",
        "            running_angle_block += angle\n",
        "            running_start_block += start\n",
        "            running_end_block += end\n",
        "            block_count += 1\n",
        "            \n",
        "        else:\n",
        "            running_angle_unblock += angle\n",
        "            running_start_unblock += start\n",
        "            running_end_unblock += end\n",
        "            unblock_count += 1\n",
        "               \n",
        "        running_test_angle += angle\n",
        "        running_test_start += start\n",
        "        running_test_end += end\n",
        "        total += 1\n",
        "        \n",
        "\n",
        "try:red_precision = tp['0']/(tp['0'] + fp['0'])\n",
        "except: red_precision = 0\n",
        "precisions.append(red_precision)\n",
        "try: red_recall = tp['0']/(tp['0'] + fn['0'])\n",
        "except: red_recall = 0\n",
        "recalls.append(red_recall)\n",
        "            \n",
        "try: green_precision = tp['1']/(tp['1'] + fp['1'])\n",
        "except: green_precision = 0\n",
        "precisions.append(green_precision)\n",
        "try: green_recall = tp['1']/(tp['1'] + fn['1'])\n",
        "except: green_recall = 0\n",
        "recalls.append(green_recall)\n",
        "            \n",
        "try: countdown_green_precision = tp['2']/(tp['2'] + fp['2'])\n",
        "except: countdown_green_precision = 0\n",
        "precisions.append(countdown_green_precision)\n",
        "try: countdown_green_recall = tp['2']/(tp['2'] + fn['2'])\n",
        "except: countdown_green_recall = 0\n",
        "recalls.append(countdown_green_recall)\n",
        "            \n",
        "try: countdown_blank_precision = tp['3']/(tp['3'] + fp['3'])\n",
        "except: countdown_blank_precision = 0\n",
        "precisions.append(countdown_blank_precision)\n",
        "try: countdown_blank_recall = tp['3']/(tp['3'] + fn['3'])\n",
        "except: countdown_blank_recall = 0\n",
        "recalls.append(countdown_blank_recall)\n",
        "            \n",
        "try: blank_precision = tp['4']/(tp['4'] + fp['4']) \n",
        "except: blank_precision = 0\n",
        "precisions.append(blank_precision)\n",
        "try: blank_recall = tp['4']/(tp['4'] + fn['4'])\n",
        "except: blank_recall = 0\n",
        "recalls.append(blank_recall)\n",
        "            \n",
        "print(\"Average loss: \" + str(running_loss/total))\n",
        "print(\"Average angle error: \" + str(running_test_angle/total))\n",
        "print(\"Average startpoint error: \" + str(running_test_start/total))\n",
        "print(\"Average endpoint error: \" + str(running_test_end/total))\n",
        "print(\"Blocked angle error: \" + str(running_angle_block/block_count))\n",
        "print(\"Blocked startpoint error: \" + str(running_start_block/block_count))\n",
        "print(\"Blocked endpoint error: \" + str(running_end_block/block_count))\n",
        "print(\"Unblocked angle error: \" + str(running_angle_unblock/unblock_count))\n",
        "print(\"Unblocked startpoint error: \" + str(running_start_unblock/unblock_count))\n",
        "print(\"Unblocked endpoint error: \" + str(running_end_unblock/unblock_count))\n",
        "print(\"Accuracy: \" + str(correct/total*100))\n",
        "\n",
        "print(\"Precisions: \" + str(precisions))\n",
        "print(\"Recalls: \" + str(recalls))\n",
        "print(\"Time Elapsed: \" + str(time.time() - start_time))"
      ],
      "metadata": {
        "id": "dcY9RzangRsM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}